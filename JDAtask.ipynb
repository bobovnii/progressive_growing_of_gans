{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JDAtask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bobovnii/progressive_growing_of_gans/blob/master/JDAtask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPwNjCKTJ3vu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "95b23653-f052-44f8-88ef-56e9eaad5abf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns                       \n",
        "import matplotlib.pyplot as plt             \n",
        "%matplotlib inline     \n",
        "sns.set(color_codes=True)\n",
        "#import pickle\n",
        "from sklearn import ensemble\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.externals import joblib"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9Dym6Z_X0mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TestDataset(df_test):\n",
        "  duplicate_rows_df = df_test[df_test.duplicated()]\n",
        "  print(\"number of duplicate rows: \", duplicate_rows_df.shape,\"if # of duplicate rows > 0, you may use df.drop_duplicates()\")\n",
        "\n",
        "  #test for nan values\n",
        "  assert not df_test.isnull().values.any(), 'nan value is found in the input dataset, you may use df.dropna()' \n",
        "\n",
        "  #test for coloumns matching\n",
        "  check = df_test.columns == ['instant', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
        "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
        "       'casual', 'registered', 'cnt']\n",
        "  assert not (False in check), 'columns names dont match'\n",
        "\n",
        "  #test for non-numerical values\n",
        "  assert not (False in df_test.applymap(np.isreal).all(1).values), 'non-numerical values were found, you may use df[~df.applymap(np.isreal).all(1)] to check them' \n",
        "\n",
        "  #check for consistency casual+gegistered == cnt\n",
        "  assert not (False in (df.registered+df.casual == df.cnt).values), 'casual+gegistered != cnt'\n",
        "\n",
        "  #check for consistency: holiday is alway not workig day\n",
        "  assert not (False in (df.holiday + df.workingday < 2).values), 'holiday is workig day!!!'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KebV-mKhf0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DataExploration(inputDataset, pathForPictures):\n",
        "  print('running data exploration')\n",
        "  df = pd.read_csv(inputDataset)\n",
        "  df = df.drop(['dteday'], axis=1)\n",
        "\n",
        "  TestDataset(df)\n",
        "  DataSetFeatures = df.describe().loc[['min','max', 'mean','50%'],:]\n",
        "  print(\"DataSet Features: \", DataSetFeatures)\n",
        "\n",
        "  #check for anomalies\n",
        "  #fig=sns.boxplot(x=df['cnt'])\n",
        "  #fig.savefig('boxplotOfBikesNumber.png')\n",
        "\n",
        "  df2= df.drop('instant',axis=1)\n",
        "  fig=df2.groupby('yr').boxplot(fontsize=20,rot=90,figsize=(20,10),patch_artist=True)\n",
        "  plt.savefig(pathForPictures+'boxplotAllForBothYears.png')\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "  Q1 = df.quantile(0.25)\n",
        "  Q3 = df.quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "\n",
        "  #possible cleaning in case of many anomalies\n",
        "  #df=df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)].shape\n",
        "\n",
        "  print('source of many anomalies is windspeed, check boxplot')\n",
        "\n",
        "  fig=sns.boxplot(x=df['windspeed'])\n",
        "  plt.savefig(pathForPictures+'boxplotWindspeed.png')\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "  #variable correlations\n",
        "\n",
        "  plt.figure(figsize=(15,10))\n",
        "  c= df.corr()\n",
        "  fig=sns.heatmap(c,cmap=\"BrBG\",annot=True)\n",
        "  plt.savefig(pathForPictures+'HeatMap.png')\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "  #plot hist and check balance\n",
        "  plt.figure(figsize=(15,10))\n",
        "  fig=df.hr.value_counts().nlargest(24).plot(kind='bar', figsize=(10,5))\n",
        "  plt.title(\"Number of inputs by hours\")\n",
        "  plt.ylabel('Number of inputs')\n",
        "  plt.xlabel('hour');\n",
        "  plt.savefig(pathForPictures+'HoursHist.png')\n",
        "  plt.clf()\n",
        "\n",
        "  plt.figure(figsize=(15,10))\n",
        "  fig=df.weathersit.value_counts().nlargest(24).plot(kind='bar', figsize=(10,5))\n",
        "  plt.title(\"Number of inputs by weather\")\n",
        "  plt.ylabel('Number of inputs')\n",
        "  plt.xlabel('weather');\n",
        "  plt.savefig(pathForPictures+'WeatherHist.png')\n",
        "  plt.clf()\n",
        "\n",
        "  plt.figure(figsize=(15,10))\n",
        "  df.yr.value_counts().nlargest(24).plot(kind='bar', figsize=(10,5))\n",
        "  plt.title(\"year\")\n",
        "  plt.ylabel('Number of inputs')\n",
        "  plt.xlabel('year');\n",
        "  plt.savefig(pathForPictures+'YearHist.png')\n",
        "  plt.clf()\n",
        "\n",
        "  #scatter plots:\n",
        "\n",
        "  df2a = df.drop(['cnt','casual','registered','instant'],axis=1)\n",
        "  df2a.index = df['cnt']\n",
        "  fig=df2a.plot(subplots=True, style='.', figsize=(10,40))\n",
        "  plt.legend(loc='best')\n",
        "  #plt.show()\n",
        "  plt.savefig(pathForPictures+'AllScatterPlots.png')\n",
        "  plt.clf()\n",
        "\n",
        "  #better scatter plots for some importnat variables\n",
        "\n",
        "  df.temp.head(5)\n",
        "  t_min= -8\n",
        "  t_max= +39\n",
        "  coloumn=(df.temp*(t_max-t_min))+t_min\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(10,6))\n",
        "  ax.scatter(coloumn, df['cnt'])\n",
        "  ax.set_xlabel('temperature')\n",
        "  ax.set_ylabel('total bike number')\n",
        "  plt.savefig(pathForPictures+'ScatterPlotTemperature.png')\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(10,6))\n",
        "  ax.scatter(df['weekday'], df['cnt'])\n",
        "  ax.set_xlabel('weekday')\n",
        "  plt.xticks((0,1,2,3,4,5,6), ('Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'))\n",
        "  ax.set_ylabel('total bike number')\n",
        "  plt.savefig(pathForPictures+'ScatterPlotDays.png')\n",
        "  plt.clf()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq_o9q_0VT6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LabelTransformation(y_in):\n",
        "  y_out=1/(0.1+y_in/y_in.max())\n",
        "  return y_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTITBoV-fmg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ReLU(x):\n",
        "    return x * (x > 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEPfhs8AEmRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def InverseLabelTransformation(y_in, maxValue):\n",
        "  y_out=ReLU((1/y_in)-0.1)*maxValue\n",
        "  return y_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaNOT7BlhPGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TrainAndTest(inputDataset, path):\n",
        "  print('running training and testing')\n",
        "  df = pd.read_csv(inputDataset)\n",
        "  df = df.drop(['dteday'], axis=1)\n",
        "\n",
        "  TestDataset(df)\n",
        "  #cleaning data, removing redundent info and separting the features from the labels\n",
        "  feat = df.drop(columns=['cnt','instant','season','casual','registered','cnt','yr'],axis=1)\n",
        "  label = df['cnt']\n",
        "\n",
        "  #variable transformation\n",
        "  sc_x = MinMaxScaler()\n",
        "  label_norm = LabelTransformation(label)\n",
        "  feat_norm = sc_x.fit_transform(feat)\n",
        "\n",
        "  #test and training splitting\n",
        "  X_train, X_test, y_train, y_test = train_test_split(feat_norm, label_norm, test_size=0.3)\n",
        "\n",
        "  #training\n",
        "  Boosting_Regression = ensemble.GradientBoostingRegressor(n_estimators = 600, max_depth = 5, min_samples_split = 2,\n",
        "          learning_rate = 0.1, loss = 'ls')\n",
        "  Boosting_Regression.fit(X_train, y_train)\n",
        "\n",
        "  #testing\n",
        "  print('score on test dataset: ',Boosting_Regression.score(X_test,y_test))\n",
        "  print('score on train dataset: ',Boosting_Regression.score(X_train,y_train))\n",
        "\n",
        "\n",
        "  # save the model to disk\n",
        "  filename = path+'Boosting_Regression_model.sav'\n",
        "\n",
        "\n",
        "\n",
        "  #joblib.dump(pipeline, 'transform_predict.joblib')\n",
        "\n",
        "\n",
        "  pickle.dump(Boosting_Regression, open(filename, 'wb'))\n",
        "\n",
        "  y_pred=Boosting_Regression.predict(X_test)\n",
        "  y_pred_train=Boosting_Regression.predict(X_train)\n",
        "\n",
        "  binwidth=50\n",
        "  plt.hist(InverseLabelTransformation(y_pred_train,700),bins=range(0, label.max() + binwidth, binwidth), label=\"train\",density='true')\n",
        "  plt.hist(InverseLabelTransformation(y_pred,700), lw=4,color='r',histtype='step',bins=range(0, label.max() + binwidth, binwidth), label=\"test\",density='true')\n",
        "  plt.title(\"Test vs Train model prediction normilized distribution\")\n",
        "  plt.ylabel('a.u.')\n",
        "  plt.xlabel('Number of bikes');\n",
        "  plt.legend()\n",
        "\n",
        "  plt.savefig(path+'TestVsTrainComparison.png')\n",
        "  plt.clf()\n",
        "\n",
        "  binwidth=50\n",
        "  plt.hist(InverseLabelTransformation(y_test,700),bins=range(0, label.max() + binwidth, binwidth), label=\"real\")\n",
        "  plt.hist(InverseLabelTransformation(y_pred,700), lw=4,color='r',histtype='step',bins=range(0, label.max() + binwidth, binwidth), label=\"predicted\")\n",
        "  plt.title(\"Test number of rented bikes\")\n",
        "  plt.ylabel('count')\n",
        "  plt.xlabel('Number of bikes');\n",
        "  plt.legend()\n",
        "\n",
        "  plt.savefig(path+'PredictedVsRealComparison.png')\n",
        "  plt.clf()\n",
        "\n",
        "  print('mean absolute error: ',metrics.mean_absolute_error(InverseLabelTransformation(y_test,700), InverseLabelTransformation(y_pred,700)))\n",
        "  print('median absolute error: ',metrics.median_absolute_error(InverseLabelTransformation(y_test,700), InverseLabelTransformation(y_pred,700))) \t\n",
        "\n",
        "\n",
        "\n",
        "  return Boosting_Regression\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYclq_VYkfIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPrediction(model, df):\n",
        "  df = df.drop(['dteday'], axis=1)\n",
        "\n",
        "  TestDataset(df)\n",
        "  #cleaning data, removing redundent info and separting the features from the labels\n",
        "  feat = df.drop(columns=['cnt','instant','season','casual','registered','cnt','yr'],axis=1)\n",
        "\n",
        "  #variable transformation\n",
        "  sc_x = MinMaxScaler()\n",
        "  feat_norm = sc_x.fit_transform(feat)\n",
        "\n",
        "  #\n",
        "  y_out=model.predict(feat_norm)\n",
        "  print(y_out)\n",
        "  y_out=InverseLabelTransformation(y_out,700)\n",
        "\n",
        "  return y_out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a6XAH3TjJBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for running on google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f073fefc-d529-4113-960d-494a3ea14b33",
        "id": "E7EMFCPttQNz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "source": [
        "inputDataset='hour.csv'\n",
        "# Data axploration and control plots\n",
        "DataExploration(inputDataset,'drive/My Drive/JDAtask/')\n",
        "# Training, testing and saving model\n",
        "TrainAndTest(inputDataset,'drive/My Drive/JDAtask/')\n",
        "\n",
        "#loading model\n",
        "filename='drive/My Drive/JDAtask/Boosting_Regression_model.sav'\n",
        "\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "dataset = pd.read_csv(inputDataset)\n",
        "\n",
        "#getting prediction\n",
        "\n",
        "getPrediction(loaded_model,dataset.loc[df.instant == 100])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running data exploration\n",
            "number of duplicate rows:  (0, 16) if # of duplicate rows > 0, you may use df.drop_duplicates()\n",
            "DataSet Features:        instant   season        yr  ...      casual  registered         cnt\n",
            "min       1.0  1.00000  0.000000  ...    0.000000    0.000000    1.000000\n",
            "max   17379.0  4.00000  1.000000  ...  367.000000  886.000000  977.000000\n",
            "mean   8690.0  2.50164  0.502561  ...   35.676218  153.786869  189.463088\n",
            "50%    8690.0  3.00000  1.000000  ...   17.000000  115.000000  142.000000\n",
            "\n",
            "[4 rows x 16 columns]\n",
            "source of many anomalies is windspeed, check boxplot\n",
            "running training and testing\n",
            "number of duplicate rows:  (0, 16) if # of duplicate rows > 0, you may use df.drop_duplicates()\n",
            "score on test dataset:  0.9391107951228764\n",
            "score on train dataset:  0.9673476830121847\n",
            "mean absolute error:  30.40638556172801\n",
            "median absolute error:  17.328310789626602\n",
            "number of duplicate rows:  (0, 16) if # of duplicate rows > 0, you may use df.drop_duplicates()\n",
            "[8.38101982]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13.52205523])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x2880 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdbirNicft9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}